{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72762a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numexpr in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.7.3)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.11.0.tar.gz (108 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from numexpr) (1.26.4)\n",
      "Building wheels for collected packages: numexpr\n",
      "  Building wheel for numexpr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numexpr: filename=numexpr-2.11.0-cp310-cp310-linux_x86_64.whl size=149340 sha256=647b1c27706dc2bfc16dd0aafac67a0b2d4314c37779867e898f72e8f7d3152c\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/a7/d0/17/e38daa1110f54ba5f7330d38440f592c063251a6456053e2ed\n",
      "Successfully built numexpr\n",
      "Installing collected packages: numexpr\n",
      "  Attempting uninstall: numexpr\n",
      "    Found existing installation: numexpr 2.7.3\n",
      "    Uninstalling numexpr-2.7.3:\n",
      "      Successfully uninstalled numexpr-2.7.3\n",
      "Successfully installed numexpr-2.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04fde3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved in S3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket_name = 'api-cdv-project'\n",
    "\n",
    "df_fake = pd.read_parquet(f's3://{bucket_name}/data/processed/fake-news.snappy.parquet')\n",
    "df_true = pd.read_parquet(f's3://{bucket_name}/data/processed/true-news.snappy.parquet')\n",
    "\n",
    "df_fake['label'] = 'fake'\n",
    "df_true['label'] = 'true'\n",
    "\n",
    "df = pd.concat([df_fake, df_true], ignore_index=True)\n",
    "df['bt_line'] = \"__label__\" + df['label'] + \" \" + df['text']\n",
    "\n",
    "train_file = 'news-train.txt'\n",
    "df.bt_line.to_csv(train_file, index=False, header=False)\n",
    "\n",
    "session.upload_data(train_file, bucket=bucket_name, key_prefix='data/input')\n",
    "print(\"Training data saved in S3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7523a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced training data saved in S3\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def balance_data(input_file, output_file):\n",
    "    data = []\n",
    "    with open(input_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            data.append(line)\n",
    "\n",
    "    class_data = defaultdict(list)\n",
    "    for line in data:\n",
    "        parts = line.split()\n",
    "        if len(parts) == 0:\n",
    "            continue\n",
    "        label = parts[0]\n",
    "        class_data[label].append(line)\n",
    "\n",
    "    max_len = max(len(v) for v in class_data.values())\n",
    "\n",
    "    balanced_data = []\n",
    "    for label, lines in class_data.items():\n",
    "        multiplier = max_len // len(lines)\n",
    "        remainder = max_len % len(lines)\n",
    "        balanced_data.extend(lines * multiplier)\n",
    "        balanced_data.extend(random.sample(lines, remainder))\n",
    "\n",
    "    random.shuffle(balanced_data)\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for line in balanced_data:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "\n",
    "balanced_train_file = \"news-train-balanced.txt\"\n",
    "balance_data(train_file, balanced_train_file)\n",
    "session.upload_data(balanced_train_file, bucket=bucket_name, key_prefix='data/input')\n",
    "print(\"Balanced training data saved in S3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f92e2120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: blazingtext-2025-07-07-20-04-32-922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 20:04:34 Starting - Starting the training job...\n",
      "2025-07-07 20:04:49 Starting - Preparing the instances for training...\n",
      "2025-07-07 20:05:10 Downloading - Downloading input data...\n",
      "2025-07-07 20:06:06 Downloading - Downloading the training image...\n",
      "2025-07-07 20:06:11 Training - Training image download completed. Training in progress...\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[07/07/2025 20:06:16 WARNING 140129556813632] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[07/07/2025 20:06:16 WARNING 140129556813632] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[07/07/2025 20:06:16 INFO 140129556813632] nvidia-smi took: 0.0252230167388916 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[07/07/2025 20:06:16 INFO 140129556813632] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[07/07/2025 20:06:16 INFO 140129556813632] Processing /opt/ml/input/data/train/news-train-balanced.txt . File size: 206.85100078582764 MB\u001b[0m\n",
      "\u001b[34mRead 10M words\u001b[0m\n",
      "\u001b[34mRead 20M words\u001b[0m\n",
      "\u001b[34mRead 30M words\u001b[0m\n",
      "\u001b[34mRead 35M words\u001b[0m\n",
      "\u001b[34mNumber of words:  195218\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0196  Progress: 2.00%  Million Words/sec: 9.46 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0186  Progress: 7.04%  Million Words/sec: 9.44 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0176  Progress: 12.04%  Million Words/sec: 9.41 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0166  Progress: 17.06%  Million Words/sec: 9.41 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0156  Progress: 22.10%  Million Words/sec: 9.39 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0146  Progress: 27.13%  Million Words/sec: 9.39 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0136  Progress: 32.13%  Million Words/sec: 9.41 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0126  Progress: 37.15%  Million Words/sec: 9.42 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0116  Progress: 42.15%  Million Words/sec: 9.42 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0106  Progress: 47.19%  Million Words/sec: 9.42 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0096  Progress: 52.21%  Million Words/sec: 9.42 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0086  Progress: 57.24%  Million Words/sec: 9.41 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0076  Progress: 62.25%  Million Words/sec: 9.42 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0065  Progress: 67.27%  Million Words/sec: 9.42 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0055  Progress: 72.28%  Million Words/sec: 9.43 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0045  Progress: 77.29%  Million Words/sec: 9.43 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0035  Progress: 82.30%  Million Words/sec: 9.43 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0025  Progress: 87.33%  Million Words/sec: 9.43 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0015  Progress: 92.34%  Million Words/sec: 9.43 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0005  Progress: 97.35%  Million Words/sec: 9.44 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 9.43 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 9.43\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 190.69\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.9995\u001b[0m\n",
      "\u001b[34mNumber of train examples: 34100\u001b[0m\n",
      "\n",
      "2025-07-07 20:09:47 Uploading - Uploading generated training model\n",
      "2025-07-07 20:10:36 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: blazingtext-2025-07-07-20-10-53-289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 325\n",
      "Billable seconds: 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name check-news-4\n",
      "INFO:sagemaker:Creating endpoint with name check-news-4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "bt_container = sagemaker.image_uris.retrieve(region=session.boto_region_name, framework='blazingtext')\n",
    "\n",
    "bt = Estimator(\n",
    "    image_uri=bt_container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size=30,\n",
    "    max_run=3600,\n",
    "    input_mode='File',\n",
    "    output_path=f's3://{bucket_name}/data/output',\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "bt.set_hyperparameters(\n",
    "    mode='supervised',\n",
    "    epochs=50,\n",
    "    min_count=2,\n",
    "    learning_rate=0.02,\n",
    "    vector_dim=100,\n",
    "    word_ngrams=2\n",
    ")\n",
    "\n",
    "balanced_train_file = \"news-train-balanced.txt\"\n",
    "train_input = TrainingInput(f's3://{bucket_name}/data/input/{balanced_train_file}', content_type='text/plain')\n",
    "\n",
    "bt.fit({'train': train_input})\n",
    "\n",
    "\n",
    "bt_model = bt.create_model()\n",
    "\n",
    "predictor = bt_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name='check-news-4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e80b2f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': ['__label__fake'], 'prob': [1.0000100135803223]}]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "title = \"Breaking News\"\n",
    "text = \"Barack Obama won president\"\n",
    "input_text = f\"{title} {text}\"\n",
    "\n",
    "\n",
    "response = predictor.predict({\"instances\": [input_text]})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b276a8-312e-47a3-932b-5fcc1cf3e468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
